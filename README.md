# Data-Crawling 

데이터 크롤링시 유용한 코드 모음
python을 활용하여 초보자도 사용하기 쉬운 코드 위주로 선정 

데이터 작업은 다음과 같이 데이터 수집 (웹 크롤링) -> 데이터 load (read csv) -> 데이터 전처리 -> 데이터 시각화(빈도 그래프, 워드 그래프) -> 데이터 분석 (머신러닝) 

1. (네이버 사이트를 활용하여) blog의 url과 title을 크롤링하여 엑셀파일로 저장
2. (엑셀파일로 저장한 내용을 불러와서 사용하는) blog의 글 내용 크롤링
3. 크롤링으로 저장된 엑셀 파일을 불러와서 내용의 형태소 분석 및 워드클라우드 작업 실행
